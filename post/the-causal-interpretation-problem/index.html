<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=generator content="Hugo 0.109.0"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><title>The Causal Interpretation Problem - Alvaro Gaiotti</title><meta name=author content="Alvaro Gaiotti"><meta name=description content="Alvaro Gaiotti's Personal Page"><meta name=keywords content="Causality,Broadbent,Causal Models,DAG"><meta property="og:title" content="The Causal Interpretation Problem"><meta name=twitter:title content="The Causal Interpretation Problem"><meta property="og:type" content="article"><meta property="og:url" content="https://alvarogaiotti.github.io/post/the-causal-interpretation-problem/"><meta property="og:description" content="This post is a rewritten version of a paper I wrote for the Philosophy of Science course I took during my Master&rsquo;s Degree.
Abstract In support of a solution based on contrastive explanation, Broadbent [Broadbent, 2013] argues that causal models cannot aspire to a solution of the Causal Interpretation Problem ( CIP). The CIP can be stated as such: “How are we to interpret statistical measures of association as causal measures of effects of exposures?&#34;. In this post I&rsquo;ll discuss Broadbent&rsquo;s theory and his objections to a causal models based solution to the CIP. I will next attempt to demonstrate why his arguments fall short and why even his method cannot be said to have resolved some of the issues he identifies in the causal models approach."><meta name=twitter:description content="This post is a rewritten version of a paper I wrote for the Philosophy of Science course I took during my Master&rsquo;s Degree.
Abstract In support of a solution based on contrastive explanation, Broadbent [Broadbent, 2013] argues that causal models cannot aspire to a solution of the Causal Interpretation Problem ( CIP). The CIP can be stated as such: “How are we to interpret statistical measures of association as causal measures of effects of exposures?&#34;. In this post I&rsquo;ll discuss Broadbent&rsquo;s theory and his objections to a causal models based solution to the CIP. I will next attempt to demonstrate why his arguments fall short and why even his method cannot be said to have resolved some of the issues he identifies in the causal models approach."><meta property="og:image" content="https://alvarogaiotti.github.io/img/causallogonew1.svg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://alvarogaiotti.github.io/img/causallogonew1.svg"><meta property="article:published_time" content="2023-01-04T00:22:37+01:00"><meta property="article:modified_time" content="2023-01-04T00:22:37+01:00"><style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}body[data-theme=auto] img.toinvert{filter:invert(80%)}}body[data-theme=dark] img{filter:brightness(60%)}</style><link rel=stylesheet href=https://alvarogaiotti.github.io/assets/css/fuji.min.b4a21b5d3eb1d0a51297e31230a65fc25e387843e45ec3a2d9176cd8d163c216d99b9b13a618b28f537c3b559ec8a408183b0fbfad48daddb9befa7d3ef90eed.css integrity="sha512-tKIbXT6x0KUSl+MSMKZfwl44eEPkXsOi2Rds2NFjwhbZm5sTphiyj1N8O1WeyKQIGDsPv61I2t25vvp9PvkO7Q=="><style>abbr{font-variant-caps:all-small-caps;font-variant-numeric:oldstyle-nums;letter-spacing:.05em;text-underline-position:under;font-style:normal}</style></head><body data-theme=auto data-theme-auto=true><script data-cfasync=false>var fujiThemeData=localStorage.getItem("fuji_data-theme");fujiThemeData?fujiThemeData!=="auto"&&document.body.setAttribute("data-theme",fujiThemeData==="dark"?"dark":"light"):localStorage.setItem("fuji_data-theme","auto")</script><header><div class="container-lg clearfix"><div class="col-12 header"><a class=title-main href=https://alvarogaiotti.github.io>Alvaro Gaiotti</a>
<span class=title-sub>Philosophy, Causality, Bridge and IT</span></div></div></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h2 class="post-item post-title"><a href=https://alvarogaiotti.github.io/post/the-causal-interpretation-problem/>The Causal Interpretation Problem</a></h2><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;2023-01-04</span>
<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;3692 words</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/tags/causality>Causality</a>&nbsp;<a href=/tags/broadbent>Broadbent</a>&nbsp;<a href=/tags/causal-models>Causal Models</a>&nbsp;<a href=/tags/dag>DAG</a>&nbsp;</span></div><div class="post-content markdown-body"><p>This post is a rewritten version of a paper I wrote for the <em>Philosophy of Science</em> course I took during my Master&rsquo;s Degree.</p><h2 id=abstract>Abstract</h2><p>In support of a solution based on contrastive explanation, Broadbent
[Broadbent, 2013] argues that causal models cannot aspire to a solution of the
Causal Interpretation Problem (
<abbr title="Causal
Interpretation Problem">CIP</abbr>). The
<abbr title="Causal Interpretation Problem">CIP</abbr> can be stated
as such: “How are we to interpret statistical measures of association as
causal measures of effects of exposures?". In this post I&rsquo;ll discuss Broadbent&rsquo;s theory
and his objections to a causal models based solution to the
<abbr title="Causal Interpretation Problem">CIP</abbr>. I
will next attempt to
demonstrate why his arguments fall short and why even his method cannot be said
to have resolved some of the issues he identifies in the causal models approach.</p><h2 id=broadbents-diagnosis-and-treatment>Broadbent&rsquo;s Diagnosis (and Treatment)</h2><p>According to Broadbent, epidemiologists are interested in causality for a variety of reasons, including to influence policymakers, to distinguish between different types of associations, to give their research a strong theoretical foundation, etc. Despite this, they avoid using causal concepts as much as they can. However, it is impossible for an epidemiologist to not indicate or make an implicit causal assumption while discussing associations, even when this avoidance is properly employed. Both practically speaking and theoretically speaking, this conclusion is essential. This leads to a problem that various authors, including Pearl, claim to have solved. Broadbent disagrees and offers a thorough analysis of the issue at hand, which is handled in the section after this one.</p><h3 id=the-cip>The CIP</h3><p>In [Broadbent 2013] the author presents an interesting challenge that epidemiologist constantly face, named the Causal Interpretation Problem (
<abbr title="Causal Interpretation Problem">CIP</abbr>):</p><blockquote><p>[&mldr;]how to understand the causal import of a measure of association on those occasions when it is used to express a causal fact, as well as a fact about an association. [Broadbent 2013]</p></blockquote><p>This is a really interesting problem which fundamentally rests on the fact that mathematical measures of association are causally neutral. As Cartwright points out: “No causes in, no causes out", so we are facing the challenge to propose an account capable of interpreting measures of association as measures of causal strength. Broadbent proposal in based on an explanatory approach to the problem.</p><h3 id=the-explanatory-approach>The Explanatory Approach</h3><p>Broadbent&rsquo;s aim is not to propose a general theory of causation, but “an account of what measures of strength of association means […] when they are used to represent […] causal facts" [Broadbent 2013]. His proposal is the following:</p><blockquote><p>A measure of strength of association is a measure of causal strength if and only if the exposure explains the measured net difference in outcome. [Broadbent 2013]</p></blockquote><p>The notion of explanation used here is based on the idea of contrastive explanation developed by Lipton, which make use of a <em>Difference Condition</em> as a necessary but not sufficient condition to characterize a good contrastive explanation. This condition is a sort of reverse of the “difference making" condition used by counterfactual theories: the difference lays not in the cause, but in how the effect is displayed, in the sense that</p><blockquote><p>[A] cause makes a difference in that had it is a difference between the effect
being as it is and the effect being different or
absent. [Broadbent 2013]</p></blockquote><p>This idea is cashed out with the following counterfactual:</p><p><em>Reverse Counterfactual</em> If
\(c\)
causes
\(e\)
then
\(\neg Oe \mathrel{\mathop\Box}\mathrel{\mkern-2.5mu\rightarrow} \neg Oc\)
. [Broadbent 2013]</p><p>Broadbent then uses this framework to propose a solution to the
<abbr title="Causal Interpretation Problem">CIP</abbr>, stating
that we must explain difference in outcomes in two population citing a
difference in exposure, which causes at least degree
\(n\)
of the outcome in the exposed group, with degree
\(n\)
being any
measure of strength of association [Broadbent 2013].</p><p>This solution seems to beg the question regarding causality (since “to cause at least degree
\(n\)
" appeals to the notion of causation), but Broadbent states that, while this is true if we take “to cause at least degree
\(n\)
" to be a general causation claim, this is not a problem if we interpret this statement as a quantification over individual cases, reducing general causal claims to quantitative claims about singular causation, avoiding circularity.</p><h2 id=causal-models>Causal Models</h2><p>In this section I will briefly describe and define causal models and their features. I will then present Broadbent&rsquo;s argument against the causal models approach for solving the
<abbr title="Causal Interpretation Problem">CIP</abbr>.</p><h3 id=what-a-causal-models-is>What a Causal Models Is</h3><p>A causal model is a mathematical model that represents causal relationships
within a system, thus enabling to predict, or infer, it&rsquo;s behaviour. It
consists of a causal structure (a set of variables
\(=V\)
and a set of pairs
\(\{\langle X, Y \rangle
; \ldots\}\)
, where
\(X, Y \in V\)
, with
the latter representing direct functional relationships between variables) and
a set of parameters assigning values to the functional relationship of each
variable based on its parent:
\(x_i = f_i(pa_i)\)
where
\(pa_i\)
are the parents of
\(x_i\)
<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. [Pearl 2009]</p><p>A causal model can assign probability values to counterfactual claims about the system, predict effects of interventions and entail probabilistic (in)dependence between variables [Hitchcock 2020]. It can be used in a reverse fashion too: given a probability distribution and some constraints is possible to determine a unique causal model (or, missing the constraints, a family of causal models) that fits the data and describes the system<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. Causal models can be represented via direct graphs, where arrows between variables represent causal relationships. An example is given in <a href=#DAG>Figure 1</a>.</p><a name=DAG></a><figure style=text-align:center><img class=toinvert src=cn1-1.svg alt=DAG1><figcaption style=font-size:80%>A Direct Acyclic Graph (<abbr title="Dyrect Acyclic Graph">DAG</abbr>)</figcaption></figure><p>Where arrow tips represent the causal relationship between variables as prescribed by the set of pairs:
\(\langle A,B\rangle; \langle A,C\rangle; \langle B,D\rangle\)
. Causal models have seen, since the advent of the multi-causal model of disease and the development of a complex and effective framework (mostly thanks to Pearl), a surge in popularity in the context of epidemiological research: thanks to their features, causal models are the best way to represent complex systems, in which multiple interaction contribute to the onset of a disease or a state of ill health. They are seen by some authors as the best way to make causal inferences and to analyze the causal dynamics of a system or phenomenon [Pearl 2009].</p><p>Broadbent argues for the incapability of the causal models approach to solve the
<abbr title="Causal Interpretation Problem">CIP</abbr>, laying out some of its problems. In the next section I will present Broadbent&rsquo;s analysis of causal models approaches to the
<abbr title="Causal Interpretation Problem">CIP</abbr>.</p><h3 id=causal-models-and-the-cip>Causal Models and the CIP</h3><p>Causal models can, in principle, offer a solution to the
<abbr title="Causal Interpretation Problem">CIP</abbr>, namely, they can interpret causal claims about population as a claim about</p><blockquote><p>[…]what would happen <em>under the assumption that certain variables have certain values and that certain relations between variables hold.</em> [Broadbent 2013]</p></blockquote><p>We can easily see that this kind of claims are quite easily yielded by causal models simply by modifying a structural equation from
\(x_i = f_i(pa_i)\)
to
\(x_i=\mathbf{x}\)
and calculating the resulting probability distribution or the values of the descendant variables.</p><p>Broadbent points out two primary problems of causal models relating to the
<abbr title="Causal Interpretation Problem">CIP</abbr>.
The first one is an epistemological problem: the question regarding what would happen translates to a question regarding the actuality of the model. If more than one model fits the data and only some of them satisfy the conditions for causation specified by the modeller, we cannot tell the correct causal interpretation until we decide which is the correct model. This is a kind of under-determination problem.</p><p>The second one is a metaphysical problem: causal models do not really answer the question regarding causation, and they
are at risk of circularity too.
The first claim is justified by the author by saying that</p><blockquote><p>One can still seek to dream up unusual causal scenarios in which the conditions for causation specified by a given
theorist are not satisfied. [Broadbent 2013]</p></blockquote><p>This claim struck me as highly unspecific and I wouldn&rsquo;t regard it as a real argument, but I will discuss it nonetheless in the next section.</p><p>The risk of circularity, following Broadbent, is embedded in causal models because of their structure: causal models are never complete, the modeller need to make decisions about what factors to capture and to use in a model, excluding some others. Those decision rely on a notion of causation, since we are excluding factors that could causally influence the outcome, but, by stipulation, do not. Since the notion of influence on which the model relies is causal, we cannot treat causal models as a way to reduce causation and explain the interpretation of measures of association as causal.</p><p>I will discuss all those problems in the following section.</p><h2 id=problems-of-broadbents-arguments-and-account>Problems of Broadbent&rsquo;s Arguments and Account</h2><p>In this section I will address the problems pointed out by Broadbent regarding causal models and try to show that they affect the explanatory approach too.
The discussion of those problems by Broadbent is vague and not in depth, so I will try to infer the underlying position and judgments that inform the arguments.</p><p>Besides, Broadbent&rsquo;s arguments do not really challenge the causal models-based proposal for solving the
<abbr title="Causal Interpretation Problem">CIP</abbr>, but they aim directly at causal models, trying to undermine them. I do not really understand this line of discussion since it seems that Broadbent aim is to challenge causal models as methods for discovering causal relationships, instead it should be to dismiss the proposed solution to the
<abbr title="Causal Interpretation Problem">CIP</abbr>. Given that, I will try to defend the causal models approach taking for granted the validity of its solution to the
<abbr title="Causal Interpretation Problem">CIP</abbr>.</p><p>After the discussion of Broadbent arguments, I will lay out some problems of Broadbent&rsquo;s proposal regarding the
<abbr title="Causal Interpretation Problem">CIP</abbr> and the general framework of the contrastive approach. The problems presented are general in nature and the argument are meant to be general arguments against some of Broadbent&rsquo;s positions, without a narrow focus.</p><h3 id=responses-to-the-epistemological-problem>Responses to the Epistemological Problem</h3><p>The epistemological problem of causal models regards the fact that we have no means to distinguish an actual causal model from a non actual causal model given that the data fits both of them, so we cannot be sure about the correctness of the causal interpretation.</p><p>While I recognize this as a big concern, I have doubts that the explanatory approach does not display the same sort of problem. It states that to explain a difference in outcome, we must cite a difference in exposure, which causes at least degree of
\(n\)
of the outcome cases.</p><p>The problem pointed out for causal models is translatable, for the explanatory approach, in the following: how do we know that an exposure is the actual cause of at least degree of
\(n\)
outcomes? If is impossible to determine with certainty if some exposure is a cause or not in a causal model (since it&rsquo;s possible that some other model fits the data, in which some different factor acts as a cause, or there is no cause at all, etc.) how is it possible that we can determine a causal role of an exposure by appealing to the claim that exposure did cause the outcome in at leas degree of
\(n\)
cases?
It is not useful to appeal to some effect-led difference making conditions, since the causal model would be able to capture those too, and if that was the way of discriminating between which variable is a cause and which is not, than we should be able to determine a unique causal model or, at least, a family of models all of which identify the same variable as a cause, but with some differences in respect of other variables&rsquo; roles<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>.</p><p>I can see a lot of problems with Broadbent&rsquo;s claim. Causal models try to capture the underlying causal structure of the phenomenon. Imagine a case in which the observable variables underdetermine the models (in the sense that more models can fit the data). This is a case where the causal dynamics of the models are not clear at all, in the sense that we cannot determine with certainty which variable is causally related to another variable. If a causal models fails in this identification, how can the explanatory approach be sure that the exposure is the cause of at least degree of
\(n\)
of the outcome observed, given that we cannot capture the underlying causal structure of the system? Could not there be another cause?</p><p>Overlooking this problem seems justified only if Broadbent gives his approach an unfair advantage: that the explanatory approach can be informed by causal judgment that humans constantly make, which can help determine the cause with more certainty, while the causal models approach is not granted this advantage. When a causal models fails to capture a system with certainty, it seems difficult to me that we could be able to identify the underlying causal structure. But the modeller can make informed guesses based on background knowledge, rules and principles, and the natural causal insight that humans possess, which can help to assign a greater probability of actuality to a specific model, not counting the already cited Minimality and Faithfulness conditions. The fact that variables can usually be time ordered helps too.</p><p>Besides, throughout the book, Broadbent is rarely concerned with truth (which seems what he means with actual). For example, truth is not the focus or the aim of good epidemiological research; instead stability is. I would argue that this sudden preoccupation for truth is instrumental for arguing against causal models. If we are faithful to the concept of stability, we should agree that if a causal model is hold to be stable then its output regarding what measure of association is to be interpreted causally must be accepted.</p><h3 id=responses-to-the-metaphysical-problem>Responses to the Metaphysical Problem</h3><p>As we saw the metaphysical problem of causal models regards their inability to answer the question about causation. I partially agree with this claim, but I find the argument that Broadbent brings to the discussion not specific and vague.</p><p>It might be true that we can construct causal scenarios in which the condition for causation are not satisfied, but I would argue that a solid causal discovery framework (e.g. [Pearl 2009]).
Besides, for what I can think of, unusual causal scenarios are rarely found in nature, and a framework for causal interpretation of association measures is not meant to give a general account of causation, as Broadbent too points out when presenting the explanatory approach. Causal models achieve a good explanation of the causal import of a measure of association in the context of epidemiology, social sciences, economics etc., their aim is not to reduce causation in general.
Anyway, those kind of claims can be made for every approach to causality, so I&rsquo;ll dismiss it without further discussion<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>.</p><h3 id=problems-of-the-explanatory-approach>Problems of the Explanatory Approach</h3><p>Broadbent proposes the explanatory approach as a solution to the
<abbr title="Causal Interpretation Problem">CIP</abbr>. While I appreciate the novelty of the proposal and the focus on effect-led difference making and the contrastive approach, I have found some problems in the proposal.</p><p>The first problem regards the appeal to singular causation in the explanatory approach. It has been extensively argued about the difficulties of determining instances of singular causation, even with the contrastive approach that Broadbent uses throughout the book [Broadbendt 2013].</p><p>The problem with the explanatory approach is that we cannot determine that a token outcome has been caused by the exposure, since this knowledge is almost always epistemically inaccessible (we cannot claim that <em>this</em> instance of smoking <em>did cause this</em> lung cancer, since we do not have the means to determine if this is true or not).</p><p>Another problem is the primitiveness of the notion of singular causation that Broadbent states, without justification. This is a quite debatable choice. As Danks points out, claims of singular causation are usually rooted in general causation claims (we say that this instance of coffee drinking caused this tremors because we know that coffee may cause tremors, as Danks points out):</p><blockquote><p>singular causation requires knowledge of (at least) both the general causation that applies in cases of this type, as well as details about this particular case. [Broadbent 2013]</p></blockquote><p>So even Broadbent proposal is at risk of circularity, nevertheless he claims it is not and addresses the problem in few sentences. Broadbent needs to justify why quantifying over singular causal claims does not lead to circularity regarding general causal claims more in depth, otherwise his position is precarious.</p><p>Regarding the contrastive approach, it can be said that there are no clear boundaries for the selection of the contrast class. The selection is informed by background knowledge: to determine the cause of a fire in a spaceship needs a different contrast class than determine the cause of a fire in a house: namely, oxygen presence is relevant for one case but not for the other [Broadbent 2013]. The selection is itself informed by causal judgements too: if we are to explain why smoking causes lung cancer, our contrast class will not comprehend people that has been exposed to asbestos for example, because we know that asbestos has a causal relationship with lung cancer.</p><p>As stated earlier: it is always possible to imagine unlikely scenarios in which
the conditions for causality do not hold, and this is a problem encountered by every
account that tries to address the
<abbr title="Causal
Interpretation Problem">CIP</abbr> and causality in general. A clear
example of some headaches that the contrastive approach may cause is the notion
of disease as defined in [Broadbent 2013], in which the selection of the
contrast class is fundamental for the correct definition of a disease but no
conditions are specified for the construction of this class, leaving no clear instruction regarding this selection.</p><p>Finally, the definition provided for the circumstances under which an exposure is deemed a cause is open to <em>not genuine causes</em>. There could be an infinite number of variables that, under this approach, could be regarded as causes. To function properly and be successful, for the explanatory approach some omitted clauses that permit us to distinguish between <em>causes</em> and <em>non causes</em> must be made explicit. Either a parasitic behavior toward causal models is required, so the model can skim and leave only actual causes for the explanatory approach to work on, or some sort of background-informed judgement is required to avoid the chance of non-causes being treated as causes.
The
former would be basically a declaration of surrender since it would state the
necessity of causal models for the discrimination between genuine and non
genuine cause, giving them a strong position to argue for a causal models-based
<abbr title="Causal Interpretation Problem">CIP</abbr> solution. The latter needs specification which is omitted and
should thus be produced. Besides, background-informed judgement are notoriously subjective and difficult to asses properly.</p><h2 id=conclusions>Conclusions</h2><p>We have seen how most of the problems highlighted by Broadbent regarding causal models and the
<abbr title="Causal Interpretation Problem">CIP</abbr> can be challenged and how even his own account suffers some of them.</p><p>I find Broadbent&rsquo;s approach really interesting and fecund: its intuitiveness and simplicity are surprising, and is absolutely effective. But the proposal is, in my opinion, still rather vague. It is in its early stages and still not thoroughly analyzed and challenged by the literature, which is mainly afferent to the epidemiological field or regards topics other than the
<abbr title="Causal Interpretation Problem">CIP</abbr> and causal interpretation.</p><p>I showed why I believe causal models approaches are not as weak as Broadbent depicts them and can therefor aspire to a solution to the
<abbr title="Causal Interpretation Problem">CIP</abbr>, especially the solution proposed by Menzies [Menzies 2004].
I think it would be wrong not to treat causal models as a good approach to causality and the
<abbr title="Causal Interpretation Problem">CIP</abbr> only because they may fail in some really strange situations.
If we had a complete framework of causality, able to capture every kind of causation regardless of the causal scenario, it would be the case to advocate for it and let go causal models. But we still do not have this framework.</p><p>Disregarding causal models for this reason would be counterproductive, since they have proved themselves highly successful and an ever-growing research effort is put on them. The raising of AI and deep neural network has proved to be fertile territory for those kind of approaches, not only in epidemiology, but in all kinds of fields.
This kind of success is not explicable if they were not able to capture, at least partially, the hidden causal nets of complex systems and phenomena, and to make causal inference and explanation easy and accessible.</p><h2 id=bibliography>Bibliography</h2><p>Broadbent, Alex. “Causation and models of disease in epidemiology.” <em>Studies in History and
Philosophy of Science Part C :Studies in History and Philosophy of Biological and Biomedical
Sciences</em> 40, 4 (2009): 302–311. <a href=http://dx.doi.org/10.1016/j.shpsc.2009.09.006 target=_blank>http://dx.doi.org/10.1016/j.shpsc.2009.09.006</a>.</p><p>&mdash;&mdash;. “Causes of causes.” <em>Philosophical Studies</em> 158, 3 (2012): 457–476.
. Philosophy of Epidemiology. London: Palgrave Macmillan UK, 2013. <a href=http://link.springer.com/10.1057/9781137315601 target=_blank>http://link.springer.com/10.1057/9781137315601</a>.</p><p>Danks, David. “Singular Causation.” In <em>The Oxford Handbook of Causal Reasoning</em>, edited by
Michael R. Waldmann. Oxford University Press, 2017, 202–219. <a href=http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780199399550.001.0001/oxfordhb-9780199399550-e-15 target=_blank>http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780199399550.001.0001/oxfordhb-9780199399550-e-15</a>.</p><p>Halpern, Joseph Y., and Judea Pearl. “Causes and explanations: A structural-model approach.
Part I: Causes.” <em>British Journal for the Philosophy of Science</em> 56, 4 (2005): 843–887. <a href=https://www.journals.uchicago.edu/doi/10.1093/bjps/axi147 target=_blank>https://www.journals.uchicago.edu/doi/10.1093/bjps/axi147</a>.</p><p>Hitchcock, Christopher. “Causal Models.” In <em>The Stanford Encyclopedia of Philosophy</em>, edited by
Edward N Zalta. Metaphysics Research Lab, Stanford University, 2020. Summer 2nd edition.
<a href=https://plato.stanford.edu/archives/sum2020/entries/causal-models/ target=_blank>https://plato.stanford.edu/archives/sum2020/entries/causal-models/</a>.</p><p>Menzies, Peter. “Causal models, token causation, and processes.” <em>Philosophy of Science</em> 71, 5 (2004): 820–832.</p><p>Pearl, Judea. Causality. Cambridge University Press, 2009.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Given the purpose of this post, disturbance components will be ignored.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>See [Hitchcock 2020], Section 4 for a thorough analysis.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>In this case the Minimality and Faithfulness condition, plus Occam&rsquo;s Razor, can help us skim and identify which causal model to use. See [Pearl 2009],
[Hitchcock 2020],
[Halpern and Pearl 2005] for a detailed presentation of those conditions.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Is always possible to construct an unlikely causal scenario which gives
rise to problems given a definition of what is a causal relation, or what is
to interpret a measure of association as having causal import. I do not mean
to dismiss this problem as not relevant. Research is always pushed by
convoluted and clever counterexamples that philosophers are able to find, so
I&rsquo;d prefer to treat them as an occasion for striving for improvement and
adjusting the account, and not as a serious undermining argument, unless the
flaw is displayed exclusively by said account. This is not the case, so I
will proceed bypassing this point [Danks 2017].&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><div class="license markdown-body"><blockquote><p>Unless otherwise noted, the content of this site is licensed under <a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0</a>.</p></blockquote></div></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/>Home</a></li><li><a href=/archives/>Archive</a></li><li><a href=/search/>Search</a></li><li><a href=/about/>About</a></li><li><a href=/contacts>Contact Me</a></li><li><a href=/index.xml>RSS</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/alvarogaiotti target=_blank><span>GitHub</span></a></li><li><a href=https://www.linkedin.com/in/alvarogaiotti target=_blank><span>LinkedIn</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/bridge/>Bridge</a></span>
<span><a href=/tags/broadbent/>Broadbent</a></span>
<span><a href=/tags/cards/>Cards</a></span>
<span><a href=/tags/causal-models/>Causal Models</a></span>
<span><a href=/tags/causality/>Causality</a></span>
<span><a href=/tags/dag/>DAG</a></span>
<span><a href=/tags/declarer-play/>Declarer play</a></span>
<span><a href=/tags/defence/>Defence</a></span>
<span><a href=/tags/endplay/>Endplay</a></span>
<span><a href=/tags/squeeze/>Squeeze</a></span>
<span><a href=/tags/world-transnational/>World Transnational</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#broadbents-diagnosis-and-treatment>Broadbent&rsquo;s Diagnosis (and Treatment)</a><ul><li><a href=#the-cip>The CIP</a></li><li><a href=#the-explanatory-approach>The Explanatory Approach</a></li></ul></li><li><a href=#causal-models>Causal Models</a><ul><li><a href=#what-a-causal-models-is>What a Causal Models Is</a></li><li><a href=#causal-models-and-the-cip>Causal Models and the CIP</a></li></ul></li><li><a href=#problems-of-broadbents-arguments-and-account>Problems of Broadbent&rsquo;s Arguments and Account</a><ul><li><a href=#responses-to-the-epistemological-problem>Responses to the Epistemological Problem</a></li><li><a href=#responses-to-the-metaphysical-problem>Responses to the Metaphysical Problem</a></li><li><a href=#problems-of-the-explanatory-approach>Problems of the Explanatory Approach</a></li></ul></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#bibliography>Bibliography</a></li></ul></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/>Home</a></li><li><a href=/archives/>Archive</a></li><li><a href=/search/>Search</a></li><li><a href=/about/>About</a></li><li><a href=/contacts>Contact Me</a></li><li><a href=/index.xml>RSS</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/alvarogaiotti target=_blank><span>GitHub</span></a></li><li><a href=https://www.linkedin.com/in/alvarogaiotti target=_blank><span>LinkedIn</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/bridge/>Bridge</a></span>
<span><a href=/tags/broadbent/>Broadbent</a></span>
<span><a href=/tags/cards/>Cards</a></span>
<span><a href=/tags/causal-models/>Causal Models</a></span>
<span><a href=/tags/causality/>Causality</a></span>
<span><a href=/tags/dag/>DAG</a></span>
<span><a href=/tags/declarer-play/>Declarer play</a></span>
<span><a href=/tags/defence/>Defence</a></span>
<span><a href=/tags/endplay/>Endplay</a></span>
<span><a href=/tags/squeeze/>Squeeze</a></span>
<span><a href=/tags/world-transnational/>World Transnational</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#broadbents-diagnosis-and-treatment>Broadbent&rsquo;s Diagnosis (and Treatment)</a><ul><li><a href=#the-cip>The CIP</a></li><li><a href=#the-explanatory-approach>The Explanatory Approach</a></li></ul></li><li><a href=#causal-models>Causal Models</a><ul><li><a href=#what-a-causal-models-is>What a Causal Models Is</a></li><li><a href=#causal-models-and-the-cip>Causal Models and the CIP</a></li></ul></li><li><a href=#problems-of-broadbents-arguments-and-account>Problems of Broadbent&rsquo;s Arguments and Account</a><ul><li><a href=#responses-to-the-epistemological-problem>Responses to the Epistemological Problem</a></li><li><a href=#responses-to-the-metaphysical-problem>Responses to the Metaphysical Problem</a></li><li><a href=#problems-of-the-explanatory-approach>Problems of the Explanatory Approach</a></li></ul></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#bibliography>Bibliography</a></li></ul></nav></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><span>&copy; 2022-2023
<a href=https://alvarogaiotti.github.io>Alvaro Gaiotti</a>
| <a href=https://github.com/alvarogaiotti/alvarogaiotti.github.io>Source code</a>
| Powered by <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a></span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js integrity="sha512-q583ppKrCRc7N5O0n2nzUiJ+suUv7Et1JGels4bXOaMFQcamPk9HjdUknZuuFjBNs7tsMuadge5k9RzdmO+1GQ==" crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js integrity="sha512-LCKPTo0gtJ74zCNMbWw04ltmujpzSR4oW+fgN+Y1YclhM5ZrHCZQAJE4quEodcI/G122sRhSGU2BsSRUZ2Gu3w==" crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js integrity="sha512-GP4x8UWxWyh4BMbyJGOGneiTbkrWEF5izsVJByzVLodP8CuJH/n936+yQDMJJrOPUHLgyPbLiGw2rXmdvGdXHA==" crossorigin=anonymous></script>
<script defer src=/assets/js/fuji.min.645f1123be695831f419ab54c1bcba327325895c740014006e57070d4f3e5d6b553e929c4b46f40ea707249e9c7f7c2a446d32a39ce7319f80a34525586a8e0f.js integrity="sha512-ZF8RI75pWDH0GatUwby6MnMliVx0ABQAblcHDU8+XWtVPpKcS0b0DqcHJJ6cf3wqRG0yo5znMZ+Ao0UlWGqODw=="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script></body></html>